---
title: "Exercise #06"
subtitle: "Fortgeschrittene Statistische Software für NF"
author: "Name (Martrikelnummer), Name (Martrikelnummer), ..."
date: "`r Sys.Date()`"
output: distill::distill_article
---

## General Remarks

-   You can submit your solutions in teams of up to 3 students.
-   Include all your team-member's names and student numbers
    (Martrikelnummern) in the `authors` field.
-   Please use the exercise template document to work on and submit your
    results.
-   Use a level 2 heading for each new exercise and answer each subtask
    next to it's bullet point or use a new level 3 heading if you want.
-   Always render the R code for your solutions and make sure to include
    the resulting data in your rendered document.
    -   Make sure to not print more than 10 rows of data (unless
        specifically instructed to).
-   Always submit both the rendered document(s) as well as your source
    Rmarkdown document. Submit the files separately on moodle, **not**
    as a zip archive.
-   Make sure to submit you render your Rmarkdown as
    `distill:distill_article` and check the final output regarding any
    issues in formatting. Formatting errors may lead to point
    deductions.

## Exercise 1: Building an R package (20 Points)

For this exercise we ask you to build an R package. We do not ask you to
build any particular R package, but leave the choice of what your R
package will do up to you, to keep it more interesting for you.

Instead of having particular tasks for you to complete, we have a list
of requirements for your final R package and submission. Please submit
an Rmd and render it as always, although you will only have to provide
the short information asked for under *Submission*.

We advise you to start early with this exercise sheet and encourage you
to reach out if you encounter issues during the creation of your
package. For detailed information on all aspects of creating an R
package, we highlight again, the [great book on R
packages](https://r-pkgs.org/) by Hadley Wickham.

We look forward to seeing the cool packages you come up with and thank
you for participating in the course!

### Functionality

a)  Create a working R package that performs the task it is intended to
    do
    
    ```{r, install required packages}
    # 0) In a clean R session ----
    #install.packages(c("devtools", "roxygen2", "randomForest", "ggplot2",
    #                  "dplyr", "tibble", "gganimate", "magrittr"))
    
    ```
    
    ```{r, create package}
    # 1) Create the skeleton in a new folder
    setwd("/home/clemi/Documents/Uni/4Semester/statsoft2/gradedExercises/06/forestSim/")
    # usethis::create_package("./forestSim")   # first install don't use it
    unloadNamespace("forestSim")
    
    # 2) Drop the files shown above into that folder
    #    (or copy‑paste them in RStudio's file explorer)
    
    # 3) Document & install
    devtools::document("../forestSim")
    devtools::install("../forestSim")
    
    # 4) Quick smoke test
    library(forestSim)                   # load newly created package
    
    sim <- simulate_forest(iris, target = "Species", ntree = 50)
    head(sim)
    plot_accuracy_growth(sim)                # should open a line plot
    
    # 5) (Optional) knit the demo vignette
    # devtools::build_vignettes("./forestSim")
    # browseVignettes("forestSim")
    
    ```
    
    ``` {r, run some more fun simulations}
    
    library(forestSim)            # load our package
    library(ggplot2)              # Load ggplot2 package
    
    # Set a seed for reproducibility
    set.seed(42)
    
    dataSet <- head(diamonds, 10000)
    
    # Create a random sample of indices for the training set (50% of the data)
    train_indices <- sample(1:nrow(dataSet), size = 0.5 * nrow(dataSet))
    
    # Split the dataset into training and testing sets
    train_set <- dataSet[train_indices, ]
    test_set <- dataSet[-train_indices, ]
    
    # Check the dimensions of the splits
    trainCount <- dim(train_set)  # Should be approximately half of the total rows
    testCount <- dim(test_set)   # Should also be approximately half of the total rows
    
    # Optionally, check the first few rows of each set
    head(train_set)
    head(test_set)    
    
    # uncommment to predict the price
    # sim2 <- simulate_forest(train_set, target = "price", ntree = 50, test = test_set)
    # find a model to predict the 
    sim2 <- simulate_forest(train_set, target = "cut", ntree = 50, test = test_set)
    head(sim2)
    plot_accuracy_growth(sim2)                # should open a line plot
    #sim <- simulate_forest(cars, target = "Species", ntree = 50)
    #head(sim)
    #plot_accuracy_growth(sim)                # should open a line plot
    ```
  1. What is OOB (Out-Of-Bag) error?
  
     * Each tree in a random forest is trained on a bootstrap sample (~63% of training data).
     * The OOB samples are the ~37% left out from that tree’s training.
     * OOB error is computed by predicting these OOB samples using that tree — no peeking at them during training.
     * It’s an internal, honest error estimate on the training data.
  
  2. What is Test set error?
  
     * Test set contains data points completely separate and independent from training.
     * However, your test set is usually smaller and might be easier or less variable than the full training data.
     * Also, your test set may be more "homogeneous" or less noisy in some respects.
    
b)  Your R package needs to be installable (test this before submitting)

c)  Your R package should contain at least 2 functions

d)  The functions in your R package should be properly documented
    according to the Roxygen convention. Each function should include an
    `@example` tag.

e)  The documentation for your package should be properly generated and
    up-to-date. After every change to the Roxygen comments of your
    functions, you will need to run `devtools::document()` again to do
    this.

f)  The `DESCRIPTION` file of your package should be properly formatted
    and contain all the required dependencies of your package. It should
    also provide an accurate `Title` and `Description` for your package.

### Possible reasons why test accuracy > OOB accuracy even with proper splitting

* Full Forest vs. OOB Predictions
* OOB accuracy is computed tree-by-tree using only the subset of trees that did not see each sample (out-of-bag trees).
* Test accuracy is computed using the entire forest — all trees — making predictions more stable and usually better.

In other words:

* OOB is a per-tree partial prediction.
* Test is a full ensemble prediction.

This difference means test predictions generally have lower variance and better accuracy.

* Size and Distribution of Test Set
* Even a random split can lead to some random variation in difficulty.
* If your test subset is smaller or has less variability, accuracy can appear artificially higher.
* Also, if the training data is very noisy or has outliers, OOB error may reflect that noise more strongly.
* OOB Error is a Conservative Estimate
* OOB error is known to be a slightly pessimistic but unbiased estimate of true test error.
* It’s a built-in “cross-validation” but with fewer trees voting per sample.
* Test set evaluation uses all trees for each sample and hence has lower error variance.

### Submission

a)  Briefly describe in one - two sentences what your R package does and
    why you decided to choose this functionality. This is just intended
    to give us some context to better understand the package.

b)  To make installation easier, your R package should be in a public
    repository on GitHub. Provide the URL to the GitHub repository
    below:

e.g. `https://github.com/<YOUR_GH_USERNAME>/<PACKAGE_REPOSITORY_NAME>`

c)  Your R package should be installable via
    `remotes::install_github()`. Before submitting your solution to this
    exercise sheet please test whether you can install your R package
    from GitHub. Provide the command below:

``` r
remotes::install_github("<YOUR_GH_USERNAME>/<PACKAGE_REPOSITORY_NAME>")
```
